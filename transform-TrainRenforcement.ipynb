{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input must be options chain day1 - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install duckdb\n",
    "!pip install tqdm\n",
    "!pip install minio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from IPython.display import clear_output\n",
    "import joblib\n",
    "import random\n",
    "import hashlib\n",
    "from src.wgangp.utils import Scaler\n",
    "from IPython.utils import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH     = './data/OptionsEOD.csv/'\n",
    "#create @ part 1\n",
    "PARQUET_PATH = './data/OptionsEOD.parquet'\n",
    "#create @ part 2\n",
    "PARQUET_STG_PATH = './data/OptionsEOD_STG.parquet'\n",
    "SCALER_COL  = [ 'UNDERLYING_LAST','STRIKE','STRIKE_DISTANCE','INTRINSIC_VALUE','DTE','C_VEGA','P_VEGA',\t'C_BID',\t'C_ASK', 'C_VOLUME',  'P_BID',\t'P_ASK', 'P_VOLUME' ]\n",
    "#create @ part 3\n",
    "OTHER_COL = ['SYMBOL','QUOTE_UNIXTIME', 'EXPIRE_UNIX']\n",
    "\n",
    "QUOTE_COL = ['C_BID',\t'C_ASK',  'P_BID',\t'P_ASK']\n",
    "VEGA_COL =  [\"C_VEGA\",\"P_VEGA\"] \n",
    "VOLUME_COL =  [\"TOTAL_VOLUME\",\"C_VOLUME\",\"P_VOLUME\"] \n",
    "\n",
    "SCALER_QUOTE_COL_INDEX = [i for i,v in enumerate(SCALER_COL) if v in QUOTE_COL]\n",
    "SCALER_VEGA_COL_INDEX = [i for i,v in enumerate(SCALER_COL) if v in VEGA_COL]\n",
    "SCALER_VOLUME_COL_INDEX = [i for i,v in enumerate(SCALER_COL) if v in VOLUME_COL]\n",
    "SCALER_OTHER_COL_INDEX = [i for i,v in enumerate(SCALER_COL) if v not in QUOTE_COL+VEGA_COL+VOLUME_COL ]\n",
    "\n",
    "\n",
    "UNIQUE_KEYS = ['SYMBOL','EXPIRE_DATE']\n",
    "H5_PATH = './data/OptTrainRenforcement/'\n",
    "START = True#True#'2010-09'#True\n",
    "BUCKET = 'tensorflow'\n",
    "\n",
    "max_option_len = 16\n",
    "#==== Create options_qoute\n",
    "options_qoute = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7f28dea254b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()  # By default, it loads the .env file from the current directory\n",
    "import duckdb\n",
    "con = duckdb.connect(database=':memory:')\n",
    "con.execute(f\"\"\"\n",
    "CREATE SECRET secretMinioProd (\n",
    "    TYPE S3,\n",
    "    KEY_ID '{os.getenv('MINIO_USER')}',\n",
    "    SECRET '{os.getenv('MINIO_SECRET')}',\n",
    "    ENDPOINT '{os.getenv('MINIO_HOST')}',\n",
    "    USE_SSL 'false',\n",
    "    URL_STYLE 'path'\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strikeZero(df,v,qv,num_rm):   \n",
    "    # First, filter based on QUOTE_DATE, SYMBOL, and EXPIRE_DATE\n",
    "    filtered_arr = df[(df['QUOTE_DATE'] == qv['QUOTE_DATE']) &\n",
    "                     (df['SYMBOL'] == v['SYMBOL']) &\n",
    "                     (df['EXPIRE_DATE'] == v['EXPIRE_DATE'])]['STRIKE'].values\n",
    "    \n",
    "    if num_rm != 0 :\n",
    "        df.loc[ (df['QUOTE_DATE'] == qv['QUOTE_DATE']) \n",
    "                & (df['SYMBOL'] == v['SYMBOL']) \n",
    "                & (df['EXPIRE_DATE'] == v['EXPIRE_DATE'])\n",
    "                & (  (df['STRIKE'].isin(filtered_arr[:num_rm])  )\n",
    "                   | (df['STRIKE'].isin(filtered_arr[-num_rm:])   )\n",
    "                  ) \n",
    "            , SCALER_COL    \n",
    "        ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ example ==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOD_CSV = pd.read_csv(CSV_PATH+\"qqq/qqq_eod_201201.txt\", engine='pyarrow')\n",
    "# EOD_CSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================Create OptionsEOD.parquet part 1========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/3] : qqq                           \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479d8795915646c982ecca798eb37d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6861519154034fc1ad3412b4a8c0ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7ea929d9c54584a3576a5eab945250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bb6d7055c0486f89d87230e74d0ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d4f6f6d774420a8b05c117dc81d901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5c2165843545bdadafe8d1884e975e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243c1232c49b405ba918fa1184dd486f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d9849cad0a4671b58b0d336fdf756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c801d10cdb774b7aa47dff55f063b12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07be22241c74e37ae40f12489c1c922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pandas_item: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f2953faed70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    for d_i,d in enumerate( os.listdir(CSV_PATH) ):\n",
    "        print(f\"[{d_i}/{len(os.listdir(CSV_PATH))}] : {d}                           \" ,end='\\r')\n",
    "        print()\n",
    "        ### tqdm_notebook\n",
    "        for f_i,f in enumerate( tqdm_notebook(os.listdir(CSV_PATH+f\"{d}/\"), desc = 'processing',position = 0  ) ):\n",
    "        #for f_i,f in enumerate( os.listdir(CSV_PATH+f\"{d}/\")[:20] ):\n",
    "            \n",
    "            DATA = pd.DataFrame([],columns=OTHER_COL+SCALER_COL)\n",
    "            if f.endswith(\".txt\") :#or f.endswith(\".csv\"):\n",
    "                ## load\n",
    "                #print( f\"[LOAD] : {CSV_PATH}{d}/{f}        \",end='\\r')\n",
    "                EOD_CSV = pd.read_csv(CSV_PATH+f\"{d}/\"+f)\n",
    "                    \n",
    "                ## rename col.\n",
    "                for c in EOD_CSV.columns:\n",
    "                    EOD_CSV = EOD_CSV.rename( columns={ c:c.strip().replace(']','').replace('[','') } )\n",
    "\n",
    "                ## add INTRINSIC_VALUE\n",
    "                EOD_CSV['INTRINSIC_VALUE'] = EOD_CSV['UNDERLYING_LAST'] - EOD_CSV['STRIKE']\n",
    "                \n",
    "                ## add symbol \n",
    "                EOD_CSV['SYMBOL'] = d.upper()                \n",
    "                ## fillnafillna\n",
    "                EOD_CSV['P_VOLUME'] = EOD_CSV['P_VOLUME'].fillna(0)\n",
    "                EOD_CSV['C_VOLUME'] = EOD_CSV['C_VOLUME'].fillna(0)\n",
    "                EOD_CSV = EOD_CSV.dropna(subset=SCALER_COL)\n",
    "            \n",
    "                \n",
    "                # date columns convert to datetime\n",
    "                for c in [\"QUOTE_READTIME\",\"QUOTE_DATE\",\"EXPIRE_DATE\"]:\n",
    "                    EOD_CSV[c] = pd.to_datetime(EOD_CSV[c])\n",
    "                \n",
    "                \n",
    "                #clean float data\n",
    "                for c in ['INTRINSIC_VALUE','C_DELTA','C_GAMMA','C_VEGA','C_THETA','C_RHO','C_IV','C_VOLUME','C_LAST','C_BID','C_ASK','STRIKE','P_BID','P_ASK','P_LAST','P_DELTA','P_GAMMA','P_VEGA','P_THETA','P_RHO','P_IV','P_VOLUME','STRIKE_DISTANCE','STRIKE_DISTANCE_PCT']:\n",
    "                    if EOD_CSV[c].dtype not in ( 'float32','float64'):\n",
    "                        EOD_CSV[c] = EOD_CSV[c].apply(str)\n",
    "                        EOD_CSV[c] = EOD_CSV[c].apply(lambda x: x.strip())\n",
    "                        EOD_CSV[c] = EOD_CSV[c].replace('', np.nan).fillna(np.nan)\n",
    "                        EOD_CSV[c] = EOD_CSV[c].astype('float64')\n",
    "                    if EOD_CSV[c].dtype == 'float32':\n",
    "                        EOD_CSV[c] = EOD_CSV[c].astype('float64')\n",
    "                        \n",
    "                # REMAIN_DAYS(int) =>  use DTE col.\n",
    "                EOD_CSV.sort_values(['QUOTE_DATE','EXPIRE_DATE','SYMBOL','STRIKE'],ascending =False ) \n",
    "\n",
    "                #==== for each EXPIRE_DATE , SYMBOL\n",
    "                keys_item = EOD_CSV[UNIQUE_KEYS].sort_values(by=UNIQUE_KEYS).drop_duplicates()\n",
    "                for j,v in tqdm_notebook(keys_item.iterrows(), desc = 'pandas_item',position = 1  ):\n",
    "                    \n",
    "                    debug = {}\n",
    "                    debug['symbo'] = v['SYMBOL']\n",
    "                    debug['exdate'] = v['EXPIRE_DATE']\n",
    "                \n",
    "                    df_Item=EOD_CSV[(EOD_CSV['SYMBOL'] == v['SYMBOL']) & (EOD_CSV['EXPIRE_DATE'] == v['EXPIRE_DATE']) ]\n",
    "                    keys_quote = df_Item[['QUOTE_DATE']].sort_values(by=['QUOTE_DATE']).drop_duplicates()[:]\n",
    "                #====/===== for each QUOTE_DATE\n",
    "                    for k,q_v in keys_quote.iterrows():\n",
    "                        #print(f\"\"\"[{f_i}/{len(os.listdir(CSV_PATH+f\"{d}/\"))}] :{v['SYMBOL']} | {v['EXPIRE_DATE']} | {k}                      \"\"\" ,end='\\r')\n",
    "                        df_filter =df_Item[(df_Item['QUOTE_DATE'] == q_v['QUOTE_DATE']) ]\n",
    "                        debug['size'] = len(df_filter) \n",
    "                        options_id = (str(v['SYMBOL'])+str(v['EXPIRE_DATE'])[:10]+str(q_v['QUOTE_DATE'])[:10]).replace(\"-\",'')\n",
    "                        if len(options_id) < 15:\n",
    "                            print(f\"\"\"ERROR : {CSV_PATH+{d}/{f}} {v['SYMBOL']}-{v['EXPIRE_DATE']}-{q_v['QUOTE_DATE']}\"\"\",end='\\r')\n",
    "                            print()\n",
    "                      \n",
    "                        #break loops : less rows             \n",
    "                        if len(df_filter) < 5 : \n",
    "                            break \n",
    "                        #add memory\n",
    "                        if options_id not in [*options_qoute.keys()]:\n",
    "                            options_qoute[options_id] = {}\n",
    "                            options_qoute[options_id]['start_price'] = df_filter['UNDERLYING_LAST'].values[0]\n",
    "                            options_qoute[options_id]['strike'] = df_filter[ df_filter['INTRINSIC_VALUE'].abs().isin(df_filter['INTRINSIC_VALUE'].abs().sort_values()[:max_option_len]) ]['STRIKE'].values\n",
    "                            options_qoute[options_id]['exp'] = df_filter['EXPIRE_DATE'].values[0]\n",
    "                        \n",
    "                        #rm index max : max_option_len\n",
    "                        #may be initstrike out of scope\n",
    "                        rm_strike_index = df_filter[ ~df_filter['STRIKE'].isin(options_qoute[options_id]['strike']) ].index\n",
    "                        df_filter = df_filter.drop(rm_strike_index)\n",
    "\n",
    "                        #break loops : after rm strike index           \n",
    "                        if len(df_filter) < 5 : \n",
    "                            break\n",
    "\n",
    "                        fix_values=df_filter[['QUOTE_UNIXTIME','QUOTE_READTIME','QUOTE_DATE','QUOTE_TIME_HOURS','UNDERLYING_LAST','UNDERLYING_LAST','EXPIRE_DATE','EXPIRE_UNIX','DTE','SYMBOL']].values[0]\n",
    "                        #set zero \n",
    "              \n",
    "                        strikeZero(df_filter,v,q_v,3 )\n",
    "                        #====filed rows to max_option_len\n",
    "                        z = 0\n",
    "                        while len(df_filter) != max_option_len :\n",
    "                            z += 1\n",
    "                            if z > 50: raise \"error\"\n",
    "                            Even= -1\n",
    "                            if (len(df_filter) % 2) == 0:\n",
    "                                Even = 0\n",
    "                            if len(df_filter) < max_option_len :\n",
    "                                zero_row = pd.DataFrame([[0]*len(df_filter.columns)], columns=df_filter.columns)\n",
    "                                if Even==0 :\n",
    "                                    df_filter = pd.concat([df_filter, zero_row], ignore_index=True)\n",
    "                                else:\n",
    "                                    df_filter = pd.concat([zero_row, df_filter], ignore_index=True)\n",
    "                            elif len(df_filter) > max_option_len :\n",
    "                                 df_filter = df_filter.drop(df_filter.index[Even])\n",
    "            \n",
    "                        #filled  0 values with values\n",
    "                        df_filter[['QUOTE_UNIXTIME','QUOTE_READTIME','QUOTE_DATE','QUOTE_TIME_HOURS','UNDERLYING_LAST','UNDERLYING_LAST','EXPIRE_DATE','EXPIRE_UNIX','DTE','SYMBOL']] = fix_values\n",
    "                        \n",
    "                        # append\n",
    "                        if len(df_filter) == max_option_len and np.sum( df_filter[OTHER_COL+SCALER_COL].isna().values ) == 0 :\n",
    "                            #DATA = np.vstack((DATA ,[df_filter[OTHER_COL+SCALER_COL]]))   \n",
    "                            df_filter_reindexed = df_filter.reindex(columns=OTHER_COL+SCALER_COL)\n",
    "                            df_filter_reindexed['QUOTE_INDEX'] = range(1, len(df_filter_reindexed) + 1)\n",
    "                            df_filter_reindexed['OPTIONS_ID'] = options_id\n",
    "                            if len(DATA) :\n",
    "                                DATA = pd.concat([DATA, df_filter_reindexed], ignore_index=True)\n",
    "                            else:\n",
    "                                DATA = df_filter_reindexed\n",
    "\n",
    "                    # #=== clear expire options_qoute\n",
    "                    for qi in list(options_qoute.keys()):\n",
    "                        if options_qoute[qi]['exp'] < q_v['QUOTE_DATE']:\n",
    "                            options_qoute.pop(qi)\n",
    "\n",
    "                    #================= save ===================\n",
    "                    # #==== dicrct save\n",
    "                    # if os.path.exists(PARQUET_PATH):\n",
    "                    #   EOD_CSV.to_parquet(PARQUET_PATH, engine='fastparquet', append=True, partition_cols=['PartitionDate'], index=False )\n",
    "                    # else:\n",
    "                    #   EOD_CSV.to_parquet(PARQUET_PATH, engine='fastparquet' , partition_cols=['PartitionDate'], index=False  )\n",
    "                    # #=== save parquet minio\n",
    "                    con.register('df_table', DATA)\n",
    "                    #parquet_file_path = f\"s3://tensorflow/renforcement/rawdata/{v['SYMBOL']}/\"\n",
    "                    parquet_file_path = f\"data/rawdata/{v['SYMBOL']}/\"\n",
    "                    os.makedirs(parquet_file_path, exist_ok=True)\n",
    "                    with io.capture_output() as captured:\n",
    "                        con.execute(f\"COPY df_table TO '{parquet_file_path}' (FORMAT PARQUET, PARTITION_BY (EXPIRE_UNIX,QUOTE_UNIXTIME), OVERWRITE_OR_IGNORE  TRUE);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C_IV'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.950980\n",
       "1         1.795070\n",
       "2         1.653790\n",
       "3         1.594120\n",
       "4         1.527140\n",
       "           ...    \n",
       "16571      0.13269\n",
       "16572      0.13116\n",
       "16573      0.13092\n",
       "16574      0.12915\n",
       "16575       0.1281\n",
       "Name: C_IV, Length: 16576, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOD_CSV['C_IV'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOD_CSV['C_IV'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_option_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "================= duckdb loaddata ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "# Initialize MinIO client\n",
    "minio_client = Minio(\n",
    "    os.getenv('MINIO_HOST'),  # Change to your MinIO server address\n",
    "    access_key=os.getenv('MINIO_USER'),\n",
    "    secret_key=os.getenv('MINIO_SECRET'),\n",
    "    secure=False  # Use False if not using HTTPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_list = []\n",
    "for _dir in minio_client.list_objects(BUCKET, prefix='renforcement/rawdata/'):\n",
    "    for file in minio_client.list_objects(BUCKET, prefix=_dir.object_name):\n",
    "        object_list.append(file.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata=con.execute(f\"\"\"\n",
    "SELECT * FROM read_parquet('s3://tensorflow/{object_list[0]}');\n",
    "\"\"\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f77a7efb8cf15d18a0cd6bbc71a8985efbc57e2467f435a53ada42728ce0a69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
